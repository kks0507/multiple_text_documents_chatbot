{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVKNAKOvFCYAbUa1S6DN3K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kks0507/multiple_text_documents_chatbot/blob/main/multi_document_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 여러 텍스트 문서와 대화할 수 있는 챗봇"
      ],
      "metadata": {
        "id": "t-XGcnIw7ajC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYWU3G7b7VPw",
        "outputId": "dd2e3b0f-6acb-406d-c8b0-dfca6387f123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.2/599.2 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for durationpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain openai tiktoken chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 여러 문서 가지고 오기"
      ],
      "metadata": {
        "id": "BB8vwB9O79OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# wget 명령어로 GitHub에서 파일을 다운로드 (techcrunch-articles.zip 파일)\n",
        "!wget -q https://github.com/kairess/toy-datasets/raw/master/techcrunch-articles.zip\n",
        "\n",
        "# 다운로드된 techcrunch-articles.zip 파일을 articles 폴더에 압축 해제\n",
        "!unzip -q techcrunch-articles.zip -d articles"
      ],
      "metadata": {
        "id": "_rlM5lls8cOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1단계. 랭체인 설정하기"
      ],
      "metadata": {
        "id": "WosN3rZO8nij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\""
      ],
      "metadata": {
        "id": "OcEVulZt8qac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install -U langchain-community # install the langchain_community package\n",
        "\n",
        "from langchain.vectorstores import Chroma # This should work after installing langchain-community\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2YzYIe59ReF",
        "outputId": "ebbeb91e-b52f-4d49-a105-7773e01fa836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.125)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.0->langchain-community) (2.9.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain-community) (2.23.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-community) (1.2.2)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.0 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2단계. 다수의 텍스트 파일 로드 후 저장하기"
      ],
      "metadata": {
        "id": "z4detc_G9azB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DirectoryLoader 클래스를 사용하여 articles 폴더에서 텍스트 파일들을 로드\n",
        "# glob=\"*.txt\"는 폴더 내에서 확장자가 .txt인 파일들만 로드함을 의미\n",
        "# loader_cls=TextLoader는 각 텍스트 파일을 개별적으로 처리하는 로더 클래스로 TextLoader를 사용\n",
        "loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
        "\n",
        "# 하나의 텍스트 파일만 로드하는 경우, loader = TextLoader('single_text_file.txt')\n",
        "\n",
        "# 텍스트 파일을 모두 로드하여 documents 리스트에 저장\n",
        "documents = loader.load()\n",
        "\n",
        "# 로드된 문서의 개수를 출력\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfDvL_IP955u",
        "outputId": "69cad256-406d-43d3-9ed7-03343f998148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3단계. 텍스트들을 1000글자 씩 분할하기"
      ],
      "metadata": {
        "id": "-8oYFVgR-jyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### documents 리스트에 있는 문서를 일정 크기의 조각으로 나누어, 총 몇 개의 조각이 생성되었는지 확인하는 작업을 수행합니다."
      ],
      "metadata": {
        "id": "7xJ_TQ5O--NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RecursiveCharacterTextSplitter 클래스를 사용해 문서를 쪼갤 준비\n",
        "# chunk_size=1000은 한 덩어리의 최대 문자 수를 1000자로 설정\n",
        "# chunk_overlap=200은 덩어리들이 겹치는 부분을 200자로 설정, 이전 덩어리와 일부 중복되게끔 만듦\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "# documents 리스트에 있는 각 문서를 설정된 chunk_size와 chunk_overlap을 기준으로 분할\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 분할된 텍스트 덩어리(chunk)의 개수를 출력\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58jCDL4A-bgI",
        "outputId": "e388a4ce-c828-41f5-f5d8-03f921913f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# texts 리스트에서 인덱스 2부터 4 이전까지의 요소(즉, 2번과 3번 요소)를 출력\n",
        "texts[2:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2Ypa12P_LNf",
        "outputId": "1ae43608-3ab1-4661-8736-facc1f432624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'articles/05-05-with-deepfloyd-generative-ai-art-gets-a-text-upgrade.txt'}, page_content='With a typical diffusion model, the model learns how to gradually subtract noise from a starting image made almost entirely of noise, moving it closer step by step to the target prompt. DeepFloyd IF performs diffusion not once but several times, generating a 64x64px image then upscaling the image to 256x256px and finally to 1024x1024px.\\n\\nWhy the need for multiple diffusion steps? DeepFloyd IF works directly with pixels, Russell explained. Diffusion models are for the most part latent diffusion models, which essentially means they work in a lower-dimensional space that represents a lot more pixels but in a less accurate way.'),\n",
              " Document(metadata={'source': 'articles/05-05-with-deepfloyd-generative-ai-art-gets-a-text-upgrade.txt'}, page_content='The other key difference between DeepFloyd IF and models such as Stable Diffusion and DALL-E 2 is that the former uses a large language model to understand and represent prompts as a vector, a basic data structure. Due to the size of the large language model embedded in DeepFloyd IF’s architecture, the model is particularly good at understanding complex prompts and even spatial relationships described in prompts (e.g. “a red cube on top of a pink sphere”).\\n\\n“It’s also very good at generating legible and correctly spelled text in images, and can even understand prompts in multiple languages,” Russell added. “Of these capabilities, the ability to generate legible text in images is perhaps the biggest breakthrough to make DeepFloyd IF stand out from other algorithms.”')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4단계. 텍스트 chunk들을 임베딩을 해준 이후 Chroma DB에 저장"
      ],
      "metadata": {
        "id": "bxfEX_OB_nDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벡터 데이터베이스를 저장할 디렉터리 경로 설정\n",
        "persist_directory = 'db'\n",
        "\n",
        "# OpenAIEmbeddings 객체 생성, 텍스트 데이터를 벡터로 변환하는 데 사용\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "# Chroma 벡터 데이터베이스를 생성하여 텍스트 문서를 임베딩으로 변환\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=texts,  # 분할된 텍스트 조각 리스트를 DB로 변환할 document\n",
        "    embedding=embedding,  # 텍스트 임베딩을 생성하는 데 사용할 OpenAIEmbeddings 객체\n",
        "    persist_directory=persist_directory  # 벡터 데이터베이스를 저장할 디렉터리\n",
        ")"
      ],
      "metadata": {
        "id": "sDc8LYfaAAJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.1) 벡터 DB 초기화 방법"
      ],
      "metadata": {
        "id": "zKPzLZftBAtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "N0dfRF8YBIz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2) 벡터 데이터베이스 로드하는 예시"
      ],
      "metadata": {
        "id": "6au9Hz7jBN72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(\n",
        "    persist_directory=persist_directory,\n",
        "    embedding_function=embedding)"
      ],
      "metadata": {
        "id": "PEXbKfqYBOPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5단계. Retriever를 사용해서 벡터 데이터베이스에서 연관된 문서 찾기\n"
      ],
      "metadata": {
        "id": "BDTOBqY6BfVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "1yYcbU8FNWsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 이 코드는 **생성형 AI(Generative AI)**에 대한 질문을 바탕으로 검색된 문서들의 출처를 출력하는 기능을 합니다.\n"
      ],
      "metadata": {
        "id": "w-EioDCKNqSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####retriever.get_relevant_documents(\"What is Generative AI?\"): 검색 기능을 제공하는 retriever 객체를 사용해 **\"What is Generative AI?\"**라는 질문에 대해 관련 문서를 검색합니다. 이 함수는 관련 문서들의 리스트를 반환합니다.\n",
        "\n",
        "#####for doc in docs: 검색된 문서 리스트(docs)를 반복하며 각 문서에 접근합니다.\n",
        "\n",
        "#####doc.metadata[\"source\"]: 각 문서의 메타데이터에서 \"source\" 필드를 가져와, 해당 문서의 출처 또는 경로 정보를 출력합니다."
      ],
      "metadata": {
        "id": "ug7IpzehNsgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 쿼리 \"What is Generative AI?\"에 대한 관련 문서를 검색 (존재하는 모든 결과 반환)\n",
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "# 검색된 문서들에 대해 반복\n",
        "for doc in docs:\n",
        "    # 각 문서의 메타데이터에서 \"source\" 필드 값을 출력 (문서의 출처를 나타냄)\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ApZfhRcNgGI",
        "outputId": "3611b5e6-dd84-436c-d7f4-4d9832b313eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-e216ad9a50a9>:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n",
            "articles/05-03-spawning-lays-out-its-plans-for-letting-creators-opt-out-of-generative-ai-training.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5-1) 결과를 k개 반환"
      ],
      "metadata": {
        "id": "cgxsb-TaN3to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chroma 벡터 데이터베이스(vectordb)에서 검색 기능을 수행하는 retriever 객체 생성\n",
        "# search_kwargs={\"k\": 3}는 검색 결과로 가장 관련성 높은 3개의 문서를 반환하도록 설정\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "fyFWx_SaTaMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"What is Generative AI?\"라는 질문에 대해 관련 문서를 검색\n",
        "docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
        "\n",
        "# 검색된 문서들에 대해 반복\n",
        "for doc in docs:\n",
        "    # 각 문서의 메타데이터에서 \"source\" 필드 값을 출력 (문서의 출처를 나타냄)\n",
        "    print(doc.metadata[\"source\"])"
      ],
      "metadata": {
        "id": "JKVCkjXfTttU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71dcde83-325f-4c31-8e30-96ca7b6c1858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "articles/05-04-slack-updates-aim-to-put-ai-at-the-center-of-the-user-experience.txt\n",
            "articles/05-03-nova-is-building-guardrails-for-generative-ai-content-to-protect-brand-integrity.txt\n",
            "articles/05-04-hugging-face-and-servicenow-release-a-free-code-generating-model.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6단계. ChatGPT 기반의 chain 형성"
      ],
      "metadata": {
        "id": "GL6sBedLTvt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RetrievalQA 객체를 생성하여 검색 기반 질의응답 시스템을 만듦\n",
        "# RetrievalQA.from_chain_type: 검색 기반 질의응답(QA) 시스템을 생성하는 함수입니다. 사용자가 쿼리를 입력하면 관련 문서를 검색하고, 그 문서를 기반으로 답변을 생성합니다.\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),  # OpenAI의 언어 모델을 사용하여 답변 생성\n",
        "    chain_type=\"stuff\",  # 사용될 체인 유형, 여기서는 'stuff' 방식을 사용 (모든 문서를 한 번에 요약)\n",
        "    retriever=retriever,  # 검색을 수행하는 retriever 객체를 연결 (관련 문서를 검색하는 기능 담당)\n",
        "    return_source_documents=True  # 결과와 함께 원본 문서도 반환하도록 설정\n",
        ")"
      ],
      "metadata": {
        "id": "axYRudyvT8ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM의 응답을 처리하고 결과와 출처를 출력하는 함수\n",
        "def process_llm_response(llm_response):\n",
        "    # 응답의 'result' 키에서 생성된 답변을 출력\n",
        "    print(llm_response['result'])\n",
        "\n",
        "    # 출처 문서를 출력하기 위한 구분선\n",
        "    print('\\n\\nSources:')\n",
        "\n",
        "    # 'source_documents' 키에 저장된 문서들의 출처를 반복하며 출력\n",
        "    for source in llm_response[\"source_documents\"]:\n",
        "        # 각 문서의 메타데이터에서 'source' 필드(출처)를 출력\n",
        "        print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "RyC3WSPMT9yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7단계. Query"
      ],
      "metadata": {
        "id": "AsM9rFAJT_By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How much money did Pando raise?\"\n",
        "# llm_response = qa_chain(query): 생성된 쿼리를 qa_chain에 전달하여 질의응답 시스템을 통해 답변을 생성합니다.\n",
        "llm_response = qa_chain(query)\n",
        "# process_llm_response(llm_response): process_llm_response 함수에 llm_response를 전달하여 LLM이 생성한 답변과 그 출처 문서를 출력합니다.\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "sPmw5GJ1UB8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9886d2-a040-434c-8630-d870cee892ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-02cd645ef8ec>:3: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  llm_response = qa_chain(query)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pando raised $30 million in its Series B round, bringing its total raised to $45 million.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_response"
      ],
      "metadata": {
        "id": "oP1lmDg0UFdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5226dfd8-5447-4362-ee23-b84eeab1c1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How much money did Pando raise?',\n",
              " 'result': ' Pando raised $30 million in its Series B round, bringing its total raised to $45 million.',\n",
              " 'source_documents': [Document(metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}, page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”'),\n",
              "  Document(metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}, page_content='The result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”'),\n",
              "  Document(metadata={'source': 'articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}, page_content='But Pando has a compelling sales pitch, judging by its momentum. The company counts Fortune 500 manufacturers and retailers — including P&G, J&J, Valvoline, Castrol, Cummins, Siemens, Danaher and Accuride — among its customer base. Since the startup’s Series A in 2020, revenue has grown 8x while the number of customers has increased 5x, Jayakrishnan said.\\n\\nAsked whether he expects expansion to continue well into the future, given the signs of potential trouble on the horizon, Jayakrishnan seemed fairly optimistic. He pointed to a Deloitte survey that found that more than 70% of manufacturing companies have been impacted by supply chain disruptions in the past year, with 90% of those companies experiencing increased costs and declining productivity.')]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who led the round in Pando?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "id": "EwDGP6y4UFyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e50b6b-4b47-440c-b350-784a0a135bb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iron Pillar and Uncorrelated Ventures led the round.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is CMA?\"\n",
        "llm_response = qa_chain(query)\n",
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3uEX0G8wTht",
        "outputId": "bb88d036-e813-4bd5-91cb-d098778d8cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CMA stands for Competition and Markets Authority, which is a government body in the UK responsible for promoting competition and preventing anti-competitive activities in markets.\n",
            "\n",
            "\n",
            "Sources:\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n",
            "articles/05-04-cma-generative-ai-review.txt\n"
          ]
        }
      ]
    }
  ]
}